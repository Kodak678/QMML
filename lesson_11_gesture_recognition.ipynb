{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b763d0",
   "metadata": {},
   "source": [
    "This session will see us attempting to apply deep learning to a Kaggle task. I hope it is an insight into the applicability of machine learning and the sorts of things it allows us to do!\n",
    "\n",
    "It will not be very theoretical, but it should be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6af5a0",
   "metadata": {},
   "source": [
    "Kaggle link: https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/overview\n",
    "\n",
    "We are classifying images based on what is happening within them (you can take many different approaches to this task), I will approach this as a gesture recognition task. We will use a prepackaged solution provided by google (mediapipe), in the future we may look at implementing this ourselves.\n",
    "\n",
    "We will use the hand gesture recognition model (https://storage.googleapis.com/mediapipe-assets/gesture_recognizer/model_card_hand_gesture_classification_with_faireness_2022.pdf) and fine tune it for our task.\n",
    "\n",
    "The data has 10 categories, which can be found in the overview page. We must add a new category labelled none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bfb504030d5ec8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1371521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a quick overview of the data and take a look at what we are working with\n",
    "# There are 10 categories, lets see how many of each we have\n",
    "\n",
    "train = './state-farm-distracted-driver-detection/imgs/train'\n",
    "\n",
    "total = 0\n",
    "cats = []\n",
    "\n",
    "for cat in sorted(os.listdir(train)):\n",
    "    if cat == '.DS_Store':\n",
    "        continue\n",
    "    print(cat, len(os.listdir(f'{train}/{cat}')))\n",
    "    cats.append(len(os.listdir(f'{train}/{cat}')))\n",
    "\n",
    "total = sum(cats)\n",
    "print(f'Total train images: {total}')\n",
    "\n",
    "# So we have around 10% for each category\n",
    "# Now lets have a look at the image size, as this matters for input to our model\n",
    "# The model requires us to input images as 192 x 192 or 224 x 224 pixel images\n",
    "test_img = cv.imread('/Users/moose/Documents/PyCharm_Projects/Karpathy_NN_course/state-farm-distracted-driver-detection/imgs/train/c0/img_34.jpg')\n",
    "print(test_img.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
