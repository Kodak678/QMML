{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b763d0",
   "metadata": {},
   "source": [
    "This session will see us attempting to apply deep learning to a Kaggle task. I hope it is an insight into the applicability of machine learning and the sorts of things it allows us to do!\n",
    "\n",
    "It will not be very theoretical, but it should be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6af5a0",
   "metadata": {},
   "source": [
    "Kaggle link: https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/overview\n",
    "\n",
    "We are classifying images based on what is happening within them (you can take many different approaches to this task), I will approach this as a gesture recognition task. We will use a prepackaged solution provided by google (mediapipe), in the future we may look at implementing this ourselves.\n",
    "\n",
    "We will use the hand gesture recognition model (https://storage.googleapis.com/mediapipe-assets/gesture_recognizer/model_card_hand_gesture_classification_with_faireness_2022.pdf) and fine tune it for our task.\n",
    "\n",
    "The data has 10 categories, which can be found in the overview page. We must add a new category labelled none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfb504030d5ec8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T17:30:35.476909Z",
     "start_time": "2024-01-29T17:30:35.450136Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcv\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Karpathy_NN_course/lib/python3.11/site-packages/mediapipe/__init__.py:17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msolutions\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msolutions\u001B[39;00m \n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtasks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtasks\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m framework\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m gpu\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Karpathy_NN_course/lib/python3.11/site-packages/mediapipe/tasks/python/__init__.py:17\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m audio\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m components\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Karpathy_NN_course/lib/python3.11/site-packages/mediapipe/tasks/python/audio/__init__.py:21\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtasks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_classifier\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmediapipe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtasks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_embedder\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m AudioClassifier \u001B[38;5;241m=\u001B[39m audio_classifier\u001B[38;5;241m.\u001B[39mAudioClassifier\n\u001B[1;32m     22\u001B[0m AudioClassifierOptions \u001B[38;5;241m=\u001B[39m audio_classifier\u001B[38;5;241m.\u001B[39mAudioClassifierOptions\n\u001B[1;32m     23\u001B[0m AudioClassifierResult \u001B[38;5;241m=\u001B[39m audio_classifier\u001B[38;5;241m.\u001B[39mAudioClassifierResult\n",
      "\u001B[0;31mNameError\u001B[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1371521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:42:03.492415Z",
     "start_time": "2024-01-29T12:42:03.456003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 2489\n",
      "c1 2267\n",
      "c2 2317\n",
      "c3 2346\n",
      "c4 2326\n",
      "c5 2312\n",
      "c6 2325\n",
      "c7 2002\n",
      "c8 1911\n",
      "c9 2129\n",
      "none 0\n",
      "Total train images: 22424\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick overview of the data and take a look at what we are working with\n",
    "# There are 10 categories, lets see how many of each we have\n",
    "\n",
    "train = './state-farm-distracted-driver-detection/imgs/train'\n",
    "\n",
    "total = 0\n",
    "cats = []\n",
    "\n",
    "for cat in sorted(os.listdir(train)):\n",
    "    if cat == '.DS_Store':\n",
    "        continue\n",
    "    print(cat, len(os.listdir(f'{train}/{cat}')))\n",
    "    cats.append(len(os.listdir(f'{train}/{cat}')))\n",
    "\n",
    "total = sum(cats)\n",
    "print(f'Total train images: {total}')\n",
    "\n",
    "# So we have around 10% for each category\n",
    "# Now lets have a look at the image size, as this matters for input to our model\n",
    "# The model requires us to input images as 192 x 192 or 224 x 224 pixel images\n",
    "test_img = cv.imread('/Users/moose/Documents/PyCharm_Projects/Karpathy_NN_course/state-farm-distracted-driver-detection/imgs/train/c0/img_34.jpg')\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12cd3faaa0a96a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T12:42:08.472781Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe_model_maker'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m tf\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gesture_recognizer\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'mediapipe_model_maker'"
     ]
    }
   ],
   "source": [
    "# Import the required libraries for mediapipe\n",
    "import os\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from mediapipe_model_maker import gesture_recognizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f8e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "venv-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
